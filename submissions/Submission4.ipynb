{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Submission4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqKhWmb1Z1An"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvwC_uN_Z5Sd"
      },
      "source": [
        "df_train = pd.read_csv('Training Data.csv')\n",
        "df_test = pd.read_csv('Test Data.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XaJpPVhZ5iN",
        "outputId": "69d8b455-fc90-447b-9db8-bc8d0741a986"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 252000 entries, 0 to 251999\n",
            "Data columns (total 13 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   Id                   252000 non-null  int64 \n",
            " 1   income               252000 non-null  int64 \n",
            " 2   age                  252000 non-null  int64 \n",
            " 3   experience           252000 non-null  int64 \n",
            " 4   married              252000 non-null  object\n",
            " 5   house_ownership      252000 non-null  object\n",
            " 6   car_ownership        252000 non-null  object\n",
            " 7   profession           252000 non-null  object\n",
            " 8   city                 252000 non-null  object\n",
            " 9   state                252000 non-null  object\n",
            " 10  current_job_years    252000 non-null  int64 \n",
            " 11  current_house_years  252000 non-null  int64 \n",
            " 12  risk_flag            252000 non-null  int64 \n",
            "dtypes: int64(7), object(6)\n",
            "memory usage: 25.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt5LQA9XZ5qZ"
      },
      "source": [
        "df_train = df_train.drop(['current_job_years','city','Id'],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_train['married'],drop_first=True)\n",
        "df_train = pd.concat([df_train.drop('married',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_train['house_ownership'],drop_first=True)\n",
        "df_train = pd.concat([df_train.drop('house_ownership',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_train['car_ownership'],drop_first=True)\n",
        "df_train = pd.concat([df_train.drop('car_ownership',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_train['profession'],drop_first=True)\n",
        "df_train = pd.concat([df_train.drop('profession',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_train['current_house_years'],drop_first=True)\n",
        "df_train = pd.concat([df_train.drop('current_house_years',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_train['state'],drop_first=True)\n",
        "df_train = pd.concat([df_train.drop('state',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "dfr = df_train['income']\n",
        "dfr = np.array(dfr)\n",
        "dfr = dfr.reshape(-1,1)\n",
        "scaler = MinMaxScaler()\n",
        "dfr = scaler.fit_transform(dfr)\n",
        "df_train['income'] = dfr\n",
        "\n",
        "dfr = df_train['age']\n",
        "dfr = np.array(dfr)\n",
        "dfr = dfr.reshape(-1,1)\n",
        "scaler = MinMaxScaler()\n",
        "dfr = scaler.fit_transform(dfr)\n",
        "df_train['age'] = dfr\n",
        "\n",
        "dfr = df_train['experience']\n",
        "dfr = np.array(dfr)\n",
        "dfr = dfr.reshape(-1,1)\n",
        "scaler = MinMaxScaler()\n",
        "dfr = scaler.fit_transform(dfr)\n",
        "df_train['experience'] = dfr"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "YkRrRmiYDMyF",
        "outputId": "e175a61e-e5d7-4caa-a638-328b0a264870"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income</th>\n",
              "      <th>age</th>\n",
              "      <th>experience</th>\n",
              "      <th>risk_flag</th>\n",
              "      <th>single</th>\n",
              "      <th>owned</th>\n",
              "      <th>rented</th>\n",
              "      <th>yes</th>\n",
              "      <th>Analyst</th>\n",
              "      <th>Architect</th>\n",
              "      <th>Army_officer</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Aviator</th>\n",
              "      <th>Biomedical_Engineer</th>\n",
              "      <th>Chartered_Accountant</th>\n",
              "      <th>Chef</th>\n",
              "      <th>Chemical_engineer</th>\n",
              "      <th>Civil_engineer</th>\n",
              "      <th>Civil_servant</th>\n",
              "      <th>Comedian</th>\n",
              "      <th>Computer_hardware_engineer</th>\n",
              "      <th>Computer_operator</th>\n",
              "      <th>Consultant</th>\n",
              "      <th>Dentist</th>\n",
              "      <th>Design_Engineer</th>\n",
              "      <th>Designer</th>\n",
              "      <th>Drafter</th>\n",
              "      <th>Economist</th>\n",
              "      <th>Engineer</th>\n",
              "      <th>Fashion_Designer</th>\n",
              "      <th>Financial_Analyst</th>\n",
              "      <th>Firefighter</th>\n",
              "      <th>Flight_attendant</th>\n",
              "      <th>Geologist</th>\n",
              "      <th>Graphic_Designer</th>\n",
              "      <th>Hotel_Manager</th>\n",
              "      <th>Industrial_Engineer</th>\n",
              "      <th>Lawyer</th>\n",
              "      <th>Librarian</th>\n",
              "      <th>Magistrate</th>\n",
              "      <th>...</th>\n",
              "      <th>Software_Developer</th>\n",
              "      <th>Statistician</th>\n",
              "      <th>Surgeon</th>\n",
              "      <th>Surveyor</th>\n",
              "      <th>Technical_writer</th>\n",
              "      <th>Technician</th>\n",
              "      <th>Technology_specialist</th>\n",
              "      <th>Web_designer</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>Assam</th>\n",
              "      <th>Bihar</th>\n",
              "      <th>Chandigarh</th>\n",
              "      <th>Chhattisgarh</th>\n",
              "      <th>Delhi</th>\n",
              "      <th>Gujarat</th>\n",
              "      <th>Haryana</th>\n",
              "      <th>Himachal_Pradesh</th>\n",
              "      <th>Jammu_and_Kashmir</th>\n",
              "      <th>Jharkhand</th>\n",
              "      <th>Karnataka</th>\n",
              "      <th>Kerala</th>\n",
              "      <th>Madhya_Pradesh</th>\n",
              "      <th>Maharashtra</th>\n",
              "      <th>Manipur</th>\n",
              "      <th>Mizoram</th>\n",
              "      <th>Odisha</th>\n",
              "      <th>Puducherry</th>\n",
              "      <th>Punjab</th>\n",
              "      <th>Rajasthan</th>\n",
              "      <th>Sikkim</th>\n",
              "      <th>Tamil_Nadu</th>\n",
              "      <th>Telangana</th>\n",
              "      <th>Tripura</th>\n",
              "      <th>Uttar_Pradesh</th>\n",
              "      <th>Uttar_Pradesh[5]</th>\n",
              "      <th>Uttarakhand</th>\n",
              "      <th>West_Bengal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.129487</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.757206</td>\n",
              "      <td>0.327586</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.398564</td>\n",
              "      <td>0.775862</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.625263</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.576454</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     income       age  experience  ...  Uttar_Pradesh[5]  Uttarakhand  West_Bengal\n",
              "0  0.129487  0.034483        0.15  ...                 0            0            0\n",
              "1  0.757206  0.327586        0.50  ...                 0            0            0\n",
              "2  0.398564  0.775862        0.20  ...                 0            0            0\n",
              "3  0.625263  0.344828        0.10  ...                 0            0            0\n",
              "4  0.576454  0.448276        0.55  ...                 0            0            0\n",
              "\n",
              "[5 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGdx0RzWZ6gZ"
      },
      "source": [
        "df_test = df_test.drop(['current_job_years','city','id'],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_test['married'],drop_first=True)\n",
        "df_test = pd.concat([df_test.drop('married',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_test['house_ownership'],drop_first=True)\n",
        "df_test = pd.concat([df_test.drop('house_ownership',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_test['car_ownership'],drop_first=True)\n",
        "df_test = pd.concat([df_test.drop('car_ownership',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_test['profession'],drop_first=True)\n",
        "df_test = pd.concat([df_test.drop('profession',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_test['current_house_years'],drop_first=True)\n",
        "df_test = pd.concat([df_test.drop('current_house_years',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "subgrade_dummies = pd.get_dummies(df_test['state'],drop_first=True)\n",
        "df_test = pd.concat([df_test.drop('state',axis=1),subgrade_dummies],axis=1)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "dfr = df_test['income']\n",
        "dfr = np.array(dfr)\n",
        "dfr = dfr.reshape(-1,1)\n",
        "scaler = MinMaxScaler()\n",
        "dfr = scaler.fit_transform(dfr)\n",
        "df_test['income'] = dfr\n",
        "\n",
        "dfr = df_test['age']\n",
        "dfr = np.array(dfr)\n",
        "dfr = dfr.reshape(-1,1)\n",
        "scaler = MinMaxScaler()\n",
        "dfr = scaler.fit_transform(dfr)\n",
        "df_test['age'] = dfr\n",
        "\n",
        "dfr = df_test['experience']\n",
        "dfr = np.array(dfr)\n",
        "dfr = dfr.reshape(-1,1)\n",
        "scaler = MinMaxScaler()\n",
        "dfr = scaler.fit_transform(dfr)\n",
        "df_test['experience'] = dfr"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnmPfumAZ6kw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "7d268885-0c15-4d5c-e0bf-471caaf9404e"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income</th>\n",
              "      <th>age</th>\n",
              "      <th>experience</th>\n",
              "      <th>single</th>\n",
              "      <th>owned</th>\n",
              "      <th>rented</th>\n",
              "      <th>yes</th>\n",
              "      <th>Analyst</th>\n",
              "      <th>Architect</th>\n",
              "      <th>Army officer</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Aviator</th>\n",
              "      <th>Biomedical Engineer</th>\n",
              "      <th>Chartered Accountant</th>\n",
              "      <th>Chef</th>\n",
              "      <th>Chemical engineer</th>\n",
              "      <th>Civil engineer</th>\n",
              "      <th>Civil servant</th>\n",
              "      <th>Comedian</th>\n",
              "      <th>Computer hardware engineer</th>\n",
              "      <th>Computer operator</th>\n",
              "      <th>Consultant</th>\n",
              "      <th>Dentist</th>\n",
              "      <th>Design Engineer</th>\n",
              "      <th>Designer</th>\n",
              "      <th>Drafter</th>\n",
              "      <th>Economist</th>\n",
              "      <th>Engineer</th>\n",
              "      <th>Fashion Designer</th>\n",
              "      <th>Financial Analyst</th>\n",
              "      <th>Firefighter</th>\n",
              "      <th>Flight attendant</th>\n",
              "      <th>Geologist</th>\n",
              "      <th>Graphic Designer</th>\n",
              "      <th>Hotel Manager</th>\n",
              "      <th>Industrial Engineer</th>\n",
              "      <th>Lawyer</th>\n",
              "      <th>Librarian</th>\n",
              "      <th>Magistrate</th>\n",
              "      <th>Mechanical engineer</th>\n",
              "      <th>...</th>\n",
              "      <th>Software Developer</th>\n",
              "      <th>Statistician</th>\n",
              "      <th>Surgeon</th>\n",
              "      <th>Surveyor</th>\n",
              "      <th>Technical writer</th>\n",
              "      <th>Technician</th>\n",
              "      <th>Technology specialist</th>\n",
              "      <th>Web designer</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>Assam</th>\n",
              "      <th>Bihar</th>\n",
              "      <th>Chandigarh</th>\n",
              "      <th>Chhattisgarh</th>\n",
              "      <th>Delhi</th>\n",
              "      <th>Gujarat</th>\n",
              "      <th>Haryana</th>\n",
              "      <th>Himachal Pradesh</th>\n",
              "      <th>Jammu and Kashmir</th>\n",
              "      <th>Jharkhand</th>\n",
              "      <th>Karnataka</th>\n",
              "      <th>Kerala</th>\n",
              "      <th>Madhya Pradesh</th>\n",
              "      <th>Maharashtra</th>\n",
              "      <th>Manipur</th>\n",
              "      <th>Mizoram</th>\n",
              "      <th>Odisha</th>\n",
              "      <th>Puducherry</th>\n",
              "      <th>Punjab</th>\n",
              "      <th>Rajasthan</th>\n",
              "      <th>Sikkim</th>\n",
              "      <th>Tamil Nadu</th>\n",
              "      <th>Telangana</th>\n",
              "      <th>Tripura</th>\n",
              "      <th>Uttar Pradesh</th>\n",
              "      <th>Uttar Pradesh[5]</th>\n",
              "      <th>Uttarakhand</th>\n",
              "      <th>West Bengal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.739054</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.120596</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.890037</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.193614</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 89 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     income       age  experience  ...  Uttar Pradesh[5]  Uttarakhand  West Bengal\n",
              "0  0.739054  0.655172        0.95  ...                 0            0            1\n",
              "1  0.120596  0.068966        0.25  ...                 0            0            0\n",
              "2  0.890037  0.500000        0.60  ...                 0            0            0\n",
              "3  0.193614  0.482759        0.45  ...                 0            0            0\n",
              "4  0.000312  0.068966        0.90  ...                 0            0            1\n",
              "\n",
              "[5 rows x 89 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTk8QKGT7ylS"
      },
      "source": [
        "X = df_train.drop('risk_flag',axis=1)\n",
        "y = df_train['risk_flag']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzl5um6M7wyv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_cv,y_train,y_cv = train_test_split(X,y,test_size=0.3,random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK3rE0csZ72A"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDfgM22MZ75c"
      },
      "source": [
        "earlystop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdX5a9_QZ7-O"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(89,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(45,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(23,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(12,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer = 'adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1UyhOZlZ8Cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c4133e-0f89-451c-ebbd-4858ca5709bb"
      },
      "source": [
        "model.fit(X_train,y_train,epochs=600,validation_data=(X_cv,y_cv),callbacks=[earlystop],verbose=1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "5513/5513 [==============================] - 19s 3ms/step - loss: 0.4092 - accuracy: 0.8744 - val_loss: 0.3671 - val_accuracy: 0.8769\n",
            "Epoch 2/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3632 - accuracy: 0.8771 - val_loss: 0.3497 - val_accuracy: 0.8769\n",
            "Epoch 3/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3490 - accuracy: 0.8786 - val_loss: 0.3349 - val_accuracy: 0.8769\n",
            "Epoch 4/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3430 - accuracy: 0.8783 - val_loss: 0.3283 - val_accuracy: 0.8769\n",
            "Epoch 5/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3378 - accuracy: 0.8776 - val_loss: 0.3226 - val_accuracy: 0.8769\n",
            "Epoch 6/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3296 - accuracy: 0.8791 - val_loss: 0.3127 - val_accuracy: 0.8769\n",
            "Epoch 7/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3285 - accuracy: 0.8772 - val_loss: 0.3132 - val_accuracy: 0.8769\n",
            "Epoch 8/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.3274 - accuracy: 0.8771 - val_loss: 0.3225 - val_accuracy: 0.8769\n",
            "Epoch 9/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3235 - accuracy: 0.8782 - val_loss: 0.3065 - val_accuracy: 0.8769\n",
            "Epoch 10/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3240 - accuracy: 0.8765 - val_loss: 0.3106 - val_accuracy: 0.8769\n",
            "Epoch 11/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3194 - accuracy: 0.8779 - val_loss: 0.3020 - val_accuracy: 0.8769\n",
            "Epoch 12/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3203 - accuracy: 0.8775 - val_loss: 0.3003 - val_accuracy: 0.8769\n",
            "Epoch 13/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3178 - accuracy: 0.8769 - val_loss: 0.2974 - val_accuracy: 0.8769\n",
            "Epoch 14/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3164 - accuracy: 0.8774 - val_loss: 0.2969 - val_accuracy: 0.8769\n",
            "Epoch 15/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3147 - accuracy: 0.8767 - val_loss: 0.2980 - val_accuracy: 0.8769\n",
            "Epoch 16/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3160 - accuracy: 0.8757 - val_loss: 0.2964 - val_accuracy: 0.8769\n",
            "Epoch 17/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3169 - accuracy: 0.8761 - val_loss: 0.2985 - val_accuracy: 0.8769\n",
            "Epoch 18/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3120 - accuracy: 0.8771 - val_loss: 0.2957 - val_accuracy: 0.8769\n",
            "Epoch 19/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3118 - accuracy: 0.8770 - val_loss: 0.2930 - val_accuracy: 0.8769\n",
            "Epoch 20/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3119 - accuracy: 0.8760 - val_loss: 0.2921 - val_accuracy: 0.8769\n",
            "Epoch 21/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3113 - accuracy: 0.8762 - val_loss: 0.2865 - val_accuracy: 0.8769\n",
            "Epoch 22/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3082 - accuracy: 0.8772 - val_loss: 0.2888 - val_accuracy: 0.8769\n",
            "Epoch 23/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3065 - accuracy: 0.8772 - val_loss: 0.2915 - val_accuracy: 0.8769\n",
            "Epoch 24/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3072 - accuracy: 0.8775 - val_loss: 0.2904 - val_accuracy: 0.8769\n",
            "Epoch 25/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3065 - accuracy: 0.8771 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
            "Epoch 26/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3060 - accuracy: 0.8760 - val_loss: 0.2892 - val_accuracy: 0.8769\n",
            "Epoch 27/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3031 - accuracy: 0.8780 - val_loss: 0.2874 - val_accuracy: 0.8769\n",
            "Epoch 28/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3014 - accuracy: 0.8776 - val_loss: 0.2853 - val_accuracy: 0.8769\n",
            "Epoch 29/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.3042 - accuracy: 0.8749 - val_loss: 0.2872 - val_accuracy: 0.8769\n",
            "Epoch 30/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.3018 - accuracy: 0.8763 - val_loss: 0.2868 - val_accuracy: 0.8769\n",
            "Epoch 31/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.3035 - accuracy: 0.8757 - val_loss: 0.2854 - val_accuracy: 0.8769\n",
            "Epoch 32/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2977 - accuracy: 0.8780 - val_loss: 0.2826 - val_accuracy: 0.8769\n",
            "Epoch 33/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2999 - accuracy: 0.8768 - val_loss: 0.2861 - val_accuracy: 0.8769\n",
            "Epoch 34/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2993 - accuracy: 0.8774 - val_loss: 0.2842 - val_accuracy: 0.8769\n",
            "Epoch 35/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2980 - accuracy: 0.8772 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
            "Epoch 36/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2984 - accuracy: 0.8775 - val_loss: 0.2800 - val_accuracy: 0.8769\n",
            "Epoch 37/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2985 - accuracy: 0.8774 - val_loss: 0.2792 - val_accuracy: 0.8769\n",
            "Epoch 38/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2974 - accuracy: 0.8765 - val_loss: 0.2752 - val_accuracy: 0.8769\n",
            "Epoch 39/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2954 - accuracy: 0.8769 - val_loss: 0.2822 - val_accuracy: 0.8769\n",
            "Epoch 40/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2968 - accuracy: 0.8763 - val_loss: 0.2788 - val_accuracy: 0.8769\n",
            "Epoch 41/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2937 - accuracy: 0.8775 - val_loss: 0.2754 - val_accuracy: 0.8769\n",
            "Epoch 42/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2921 - accuracy: 0.8787 - val_loss: 0.2801 - val_accuracy: 0.8769\n",
            "Epoch 43/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2921 - accuracy: 0.8786 - val_loss: 0.2800 - val_accuracy: 0.8769\n",
            "Epoch 44/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2958 - accuracy: 0.8767 - val_loss: 0.2744 - val_accuracy: 0.8769\n",
            "Epoch 45/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2953 - accuracy: 0.8762 - val_loss: 0.2756 - val_accuracy: 0.8769\n",
            "Epoch 46/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2900 - accuracy: 0.8782 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
            "Epoch 47/600\n",
            "5513/5513 [==============================] - 14s 3ms/step - loss: 0.2910 - accuracy: 0.8778 - val_loss: 0.2734 - val_accuracy: 0.8769\n",
            "Epoch 48/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2926 - accuracy: 0.8767 - val_loss: 0.2798 - val_accuracy: 0.8769\n",
            "Epoch 49/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2919 - accuracy: 0.8769 - val_loss: 0.2732 - val_accuracy: 0.8769\n",
            "Epoch 50/600\n",
            "5513/5513 [==============================] - 18s 3ms/step - loss: 0.2928 - accuracy: 0.8765 - val_loss: 0.2747 - val_accuracy: 0.8769\n",
            "Epoch 51/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2916 - accuracy: 0.8770 - val_loss: 0.2749 - val_accuracy: 0.8769\n",
            "Epoch 52/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2905 - accuracy: 0.8779 - val_loss: 0.2763 - val_accuracy: 0.8769\n",
            "Epoch 53/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2906 - accuracy: 0.8777 - val_loss: 0.2734 - val_accuracy: 0.8769\n",
            "Epoch 54/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2937 - accuracy: 0.8751 - val_loss: 0.2741 - val_accuracy: 0.8769\n",
            "Epoch 55/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2915 - accuracy: 0.8763 - val_loss: 0.2743 - val_accuracy: 0.8769\n",
            "Epoch 56/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2878 - accuracy: 0.8788 - val_loss: 0.2763 - val_accuracy: 0.8769\n",
            "Epoch 57/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2895 - accuracy: 0.8760 - val_loss: 0.2792 - val_accuracy: 0.8769\n",
            "Epoch 58/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2906 - accuracy: 0.8765 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
            "Epoch 59/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2885 - accuracy: 0.8778 - val_loss: 0.2704 - val_accuracy: 0.8769\n",
            "Epoch 60/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2888 - accuracy: 0.8770 - val_loss: 0.2709 - val_accuracy: 0.8769\n",
            "Epoch 61/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2896 - accuracy: 0.8761 - val_loss: 0.2778 - val_accuracy: 0.8769\n",
            "Epoch 62/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2899 - accuracy: 0.8767 - val_loss: 0.2725 - val_accuracy: 0.8769\n",
            "Epoch 63/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2882 - accuracy: 0.8765 - val_loss: 0.2744 - val_accuracy: 0.8769\n",
            "Epoch 64/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2850 - accuracy: 0.8771 - val_loss: 0.2682 - val_accuracy: 0.8769\n",
            "Epoch 65/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2862 - accuracy: 0.8785 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
            "Epoch 66/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2864 - accuracy: 0.8774 - val_loss: 0.2729 - val_accuracy: 0.8769\n",
            "Epoch 67/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2891 - accuracy: 0.8768 - val_loss: 0.2722 - val_accuracy: 0.8769\n",
            "Epoch 68/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2865 - accuracy: 0.8777 - val_loss: 0.2690 - val_accuracy: 0.8769\n",
            "Epoch 69/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2859 - accuracy: 0.8780 - val_loss: 0.2692 - val_accuracy: 0.8769\n",
            "Epoch 70/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2845 - accuracy: 0.8784 - val_loss: 0.2734 - val_accuracy: 0.8769\n",
            "Epoch 71/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2876 - accuracy: 0.8766 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
            "Epoch 72/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2840 - accuracy: 0.8774 - val_loss: 0.2710 - val_accuracy: 0.8769\n",
            "Epoch 73/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2870 - accuracy: 0.8764 - val_loss: 0.2688 - val_accuracy: 0.8769\n",
            "Epoch 74/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2852 - accuracy: 0.8783 - val_loss: 0.2709 - val_accuracy: 0.8769\n",
            "Epoch 75/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2835 - accuracy: 0.8784 - val_loss: 0.2703 - val_accuracy: 0.8769\n",
            "Epoch 76/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2849 - accuracy: 0.8772 - val_loss: 0.2676 - val_accuracy: 0.8769\n",
            "Epoch 77/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2856 - accuracy: 0.8772 - val_loss: 0.2729 - val_accuracy: 0.8769\n",
            "Epoch 78/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2854 - accuracy: 0.8773 - val_loss: 0.2675 - val_accuracy: 0.8769\n",
            "Epoch 79/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2858 - accuracy: 0.8774 - val_loss: 0.2736 - val_accuracy: 0.8769\n",
            "Epoch 80/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2859 - accuracy: 0.8774 - val_loss: 0.2729 - val_accuracy: 0.8769\n",
            "Epoch 81/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2888 - accuracy: 0.8754 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
            "Epoch 82/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2849 - accuracy: 0.8772 - val_loss: 0.2694 - val_accuracy: 0.8769\n",
            "Epoch 83/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2859 - accuracy: 0.8761 - val_loss: 0.2678 - val_accuracy: 0.8769\n",
            "Epoch 84/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2836 - accuracy: 0.8773 - val_loss: 0.2688 - val_accuracy: 0.8769\n",
            "Epoch 85/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2833 - accuracy: 0.8764 - val_loss: 0.2666 - val_accuracy: 0.8769\n",
            "Epoch 86/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2831 - accuracy: 0.8772 - val_loss: 0.2647 - val_accuracy: 0.8769\n",
            "Epoch 87/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2856 - accuracy: 0.8761 - val_loss: 0.2685 - val_accuracy: 0.8769\n",
            "Epoch 88/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2833 - accuracy: 0.8770 - val_loss: 0.2686 - val_accuracy: 0.8769\n",
            "Epoch 89/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2817 - accuracy: 0.8770 - val_loss: 0.2649 - val_accuracy: 0.8769\n",
            "Epoch 90/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2821 - accuracy: 0.8769 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
            "Epoch 91/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2817 - accuracy: 0.8775 - val_loss: 0.2677 - val_accuracy: 0.8769\n",
            "Epoch 92/600\n",
            "5513/5513 [==============================] - 18s 3ms/step - loss: 0.2825 - accuracy: 0.8774 - val_loss: 0.2682 - val_accuracy: 0.8769\n",
            "Epoch 93/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2816 - accuracy: 0.8773 - val_loss: 0.2681 - val_accuracy: 0.8769\n",
            "Epoch 94/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2804 - accuracy: 0.8780 - val_loss: 0.2655 - val_accuracy: 0.8769\n",
            "Epoch 95/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2817 - accuracy: 0.8768 - val_loss: 0.2665 - val_accuracy: 0.8769\n",
            "Epoch 96/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2813 - accuracy: 0.8760 - val_loss: 0.2653 - val_accuracy: 0.8769\n",
            "Epoch 97/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2819 - accuracy: 0.8779 - val_loss: 0.2697 - val_accuracy: 0.8769\n",
            "Epoch 98/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2788 - accuracy: 0.8787 - val_loss: 0.2698 - val_accuracy: 0.8769\n",
            "Epoch 99/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2804 - accuracy: 0.8770 - val_loss: 0.2640 - val_accuracy: 0.8769\n",
            "Epoch 100/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2792 - accuracy: 0.8771 - val_loss: 0.2687 - val_accuracy: 0.8769\n",
            "Epoch 101/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2833 - accuracy: 0.8753 - val_loss: 0.2659 - val_accuracy: 0.8769\n",
            "Epoch 102/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2814 - accuracy: 0.8758 - val_loss: 0.2696 - val_accuracy: 0.8769\n",
            "Epoch 103/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2798 - accuracy: 0.8770 - val_loss: 0.2664 - val_accuracy: 0.8769\n",
            "Epoch 104/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2795 - accuracy: 0.8779 - val_loss: 0.2676 - val_accuracy: 0.8769\n",
            "Epoch 105/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2815 - accuracy: 0.8765 - val_loss: 0.2701 - val_accuracy: 0.8769\n",
            "Epoch 106/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2799 - accuracy: 0.8770 - val_loss: 0.2666 - val_accuracy: 0.8769\n",
            "Epoch 107/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2800 - accuracy: 0.8776 - val_loss: 0.2671 - val_accuracy: 0.8769\n",
            "Epoch 108/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2808 - accuracy: 0.8771 - val_loss: 0.2722 - val_accuracy: 0.8769\n",
            "Epoch 109/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2817 - accuracy: 0.8752 - val_loss: 0.2660 - val_accuracy: 0.8769\n",
            "Epoch 110/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2798 - accuracy: 0.8770 - val_loss: 0.2646 - val_accuracy: 0.8769\n",
            "Epoch 111/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2800 - accuracy: 0.8782 - val_loss: 0.2646 - val_accuracy: 0.8769\n",
            "Epoch 112/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2796 - accuracy: 0.8774 - val_loss: 0.2654 - val_accuracy: 0.8769\n",
            "Epoch 113/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2817 - accuracy: 0.8754 - val_loss: 0.2658 - val_accuracy: 0.8769\n",
            "Epoch 114/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2815 - accuracy: 0.8758 - val_loss: 0.2647 - val_accuracy: 0.8769\n",
            "Epoch 115/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2788 - accuracy: 0.8776 - val_loss: 0.2647 - val_accuracy: 0.8769\n",
            "Epoch 116/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2785 - accuracy: 0.8755 - val_loss: 0.2628 - val_accuracy: 0.8769\n",
            "Epoch 117/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2791 - accuracy: 0.8772 - val_loss: 0.2669 - val_accuracy: 0.8769\n",
            "Epoch 118/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2783 - accuracy: 0.8773 - val_loss: 0.2647 - val_accuracy: 0.8769\n",
            "Epoch 119/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2779 - accuracy: 0.8773 - val_loss: 0.2646 - val_accuracy: 0.8769\n",
            "Epoch 120/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2773 - accuracy: 0.8775 - val_loss: 0.2643 - val_accuracy: 0.8769\n",
            "Epoch 121/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2799 - accuracy: 0.8771 - val_loss: 0.2632 - val_accuracy: 0.8769\n",
            "Epoch 122/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2763 - accuracy: 0.8777 - val_loss: 0.2661 - val_accuracy: 0.8769\n",
            "Epoch 123/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2799 - accuracy: 0.8780 - val_loss: 0.2641 - val_accuracy: 0.8769\n",
            "Epoch 124/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2772 - accuracy: 0.8772 - val_loss: 0.2660 - val_accuracy: 0.8769\n",
            "Epoch 125/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2759 - accuracy: 0.8775 - val_loss: 0.2648 - val_accuracy: 0.8769\n",
            "Epoch 126/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2750 - accuracy: 0.8771 - val_loss: 0.2629 - val_accuracy: 0.8769\n",
            "Epoch 127/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2771 - accuracy: 0.8766 - val_loss: 0.2696 - val_accuracy: 0.8769\n",
            "Epoch 128/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2790 - accuracy: 0.8754 - val_loss: 0.2664 - val_accuracy: 0.8769\n",
            "Epoch 129/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2751 - accuracy: 0.8780 - val_loss: 0.2699 - val_accuracy: 0.8769\n",
            "Epoch 130/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2755 - accuracy: 0.8768 - val_loss: 0.2769 - val_accuracy: 0.8769\n",
            "Epoch 131/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2760 - accuracy: 0.8773 - val_loss: 0.2672 - val_accuracy: 0.8769\n",
            "Epoch 132/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2803 - accuracy: 0.8761 - val_loss: 0.2692 - val_accuracy: 0.8769\n",
            "Epoch 133/600\n",
            "5513/5513 [==============================] - 19s 3ms/step - loss: 0.2782 - accuracy: 0.8762 - val_loss: 0.2651 - val_accuracy: 0.8769\n",
            "Epoch 134/600\n",
            "5513/5513 [==============================] - 18s 3ms/step - loss: 0.2776 - accuracy: 0.8774 - val_loss: 0.2618 - val_accuracy: 0.8769\n",
            "Epoch 135/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2778 - accuracy: 0.8766 - val_loss: 0.2637 - val_accuracy: 0.8769\n",
            "Epoch 136/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2762 - accuracy: 0.8776 - val_loss: 0.2676 - val_accuracy: 0.8769\n",
            "Epoch 137/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2785 - accuracy: 0.8765 - val_loss: 0.2642 - val_accuracy: 0.8769\n",
            "Epoch 138/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2782 - accuracy: 0.8768 - val_loss: 0.2652 - val_accuracy: 0.8769\n",
            "Epoch 139/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2800 - accuracy: 0.8751 - val_loss: 0.2650 - val_accuracy: 0.8769\n",
            "Epoch 140/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2760 - accuracy: 0.8778 - val_loss: 0.2654 - val_accuracy: 0.8769\n",
            "Epoch 141/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2762 - accuracy: 0.8768 - val_loss: 0.2700 - val_accuracy: 0.8769\n",
            "Epoch 142/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2774 - accuracy: 0.8767 - val_loss: 0.2621 - val_accuracy: 0.8769\n",
            "Epoch 143/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2768 - accuracy: 0.8769 - val_loss: 0.2689 - val_accuracy: 0.8769\n",
            "Epoch 144/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2756 - accuracy: 0.8780 - val_loss: 0.2723 - val_accuracy: 0.8769\n",
            "Epoch 145/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2774 - accuracy: 0.8770 - val_loss: 0.2637 - val_accuracy: 0.8769\n",
            "Epoch 146/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2762 - accuracy: 0.8765 - val_loss: 0.2652 - val_accuracy: 0.8769\n",
            "Epoch 147/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2768 - accuracy: 0.8765 - val_loss: 0.2644 - val_accuracy: 0.8769\n",
            "Epoch 148/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2766 - accuracy: 0.8764 - val_loss: 0.2667 - val_accuracy: 0.8769\n",
            "Epoch 149/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2772 - accuracy: 0.8760 - val_loss: 0.2651 - val_accuracy: 0.8769\n",
            "Epoch 150/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2782 - accuracy: 0.8766 - val_loss: 0.2681 - val_accuracy: 0.8769\n",
            "Epoch 151/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2757 - accuracy: 0.8776 - val_loss: 0.2642 - val_accuracy: 0.8769\n",
            "Epoch 152/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2729 - accuracy: 0.8781 - val_loss: 0.2662 - val_accuracy: 0.8769\n",
            "Epoch 153/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2765 - accuracy: 0.8770 - val_loss: 0.2648 - val_accuracy: 0.8769\n",
            "Epoch 154/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2734 - accuracy: 0.8783 - val_loss: 0.2675 - val_accuracy: 0.8769\n",
            "Epoch 155/600\n",
            "5513/5513 [==============================] - 17s 3ms/step - loss: 0.2768 - accuracy: 0.8766 - val_loss: 0.2681 - val_accuracy: 0.8769\n",
            "Epoch 156/600\n",
            "5513/5513 [==============================] - 16s 3ms/step - loss: 0.2740 - accuracy: 0.8778 - val_loss: 0.2686 - val_accuracy: 0.8769\n",
            "Epoch 157/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2768 - accuracy: 0.8769 - val_loss: 0.2652 - val_accuracy: 0.8769\n",
            "Epoch 158/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2740 - accuracy: 0.8768 - val_loss: 0.2656 - val_accuracy: 0.8769\n",
            "Epoch 159/600\n",
            "5513/5513 [==============================] - 15s 3ms/step - loss: 0.2742 - accuracy: 0.8767 - val_loss: 0.2636 - val_accuracy: 0.8769\n",
            "Epoch 00159: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2f68057e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHtAnwPFZ8HQ"
      },
      "source": [
        "df_loss = pd.DataFrame(model.history.history)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxkiPt2YZ8MD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "6d182bb0-52e6-498b-f0ec-55f819e1ac7f"
      },
      "source": [
        "df_loss.plot()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f64dfce50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5fn/8fc9a/Y9ZAUS9n1RZBFFQVGkCGpFRL+00KpfrUtbrRbX8lVrrd20vWgtteJexIX+qFpxARcUIaDIvoYACUv2PZnM8vz+mCEGCBAgYZLhfl1XLuac88w5d54wnznznGXEGINSSqmOzxLsApRSSrUODXSllAoRGuhKKRUiNNCVUipEaKArpVSI0EBXSqkQ0aJAF5EJIrJVRHaIyOxmlncVkY9FZJ2IfCIima1fqlJKqeORE52HLiJWYBswHsgHcoDpxphNTdq8AbxjjHlRRMYBs4wxM4633qSkJJOVlXWa5Sul1NllzZo1xcaY5OaW2Vrw/OHADmNMLoCILACmAJuatOkH3B14vAz494lWmpWVxerVq1uweaWUUoeIyO5jLWvJkEsGsLfJdH5gXlPfAtcEHl8NRItI4skUqZRS6vS01kHRXwAXicg3wEVAAeA9spGI3CIiq0VkdVFRUSttWimlFLQs0AuAzk2mMwPzGhlj9hljrjHGDAUeDMwrP3JFxph5xphhxphhycnNDgEppZQ6RS0J9Bygp4hki4gDuB5Y3LSBiCSJyKF13Q8837plKqWUOpETBroxxgPcASwBNgMLjTEbReRREZkcaHYxsFVEtgEpwK/bqF6llFLHcMLTFtvKsGHDjJ7lopRSJ0dE1hhjhjW3TK8UVUqpENGS89DblQOP3I9r4zrwuMDnDnY5Sil10pwDh5L6xNOtvt4OF+iU7oDCzcGuQimlTl1N29wdpcMFeuoTz0BNEcRkQkQCiAS7JKWUahc6XKATk+7/UUopdRg9KKqUUiFCA10ppUKEBrpSSoUIDXSllAoRGuhKKRUiNNCVUipEaKArpVSI0EBXSqkQoYGulFIhQgNdKaVChAa6UkqFCA10pZQKERroSikVIjTQlVIqRGigK6VUiNBAV0qpEKGBrpRSIUIDXSmlQkSLAl1EJojIVhHZISKzm1neRUSWicg3IrJORCa2fqlKKaWO54SBLiJWYC5wBdAPmC4i/Y5o9hCw0BgzFLge+GtrF6qUUur4WrKHPhzYYYzJNcY0AAuAKUe0MUBM4HEssK/1SlRKKdUStha0yQD2NpnOB0Yc0WYO8IGI3AlEApe2SnVKKaVarLUOik4HXjDGZAITgZdF5Kh1i8gtIrJaRFYXFRW10qaVUkpBywK9AOjcZDozMK+pHwMLAYwxK4AwIOnIFRlj5hljhhljhiUnJ59axUoppZrVkkDPAXqKSLaIOPAf9Fx8RJs9wCUAItIXf6DrLrhSSp1BJwx0Y4wHuANYAmzGfzbLRhF5VEQmB5rdA9wsIt8C/wJmGmNMWxWtlFLqaC05KIox5j3gvSPmPdLk8SZgdOuWppRS6mTolaJKKRUiNNCVUipEaKArpVSI0EBXSqkQoYGulFIhQgNdKaVChAa6UkqFCA10pZQKERroSikVIjTQlVIqRGigK6VUiNBAV0qpEKGBrpRSIUIDXSmlQoQGulJKhQgNdKWUChEa6EopFSI00JVSKkRooCulVIjQQFdKqRChga6UUiFCA10ppUKEBrpSSoWIFgW6iEwQka0iskNEZjez/E8isjbws01Eylu/VKWUUsdjO1EDEbECc4HxQD6QIyKLjTGbDrUxxvy8Sfs7gaFtUKtSSqnjaMke+nBghzEm1xjTACwAphyn/XTgX61RnFJKqZZrSaBnAHubTOcH5h1FRLoC2cDS0y9NKaXUyWjtg6LXA28aY7zNLRSRW0RktYisLioqauVNK6XU2a0lgV4AdG4ynRmY15zrOc5wizFmnjFmmDFmWHJycsurVEopdUItCfQcoKeIZIuIA39oLz6ykYj0AeKBFa1bolJKqZY4YaAbYzzAHcASYDOw0BizUUQeFZHJTZpeDywwxpi2KVUppdTxnPC0RQBjzHvAe0fMe+SI6TmtV5ZSSqmTpVeKKqVUiNBAV0qpEKGBrpRSIUIDXSmlQoQGulJKhYgWneWilAp9breb/Px86uvrg12KAsLCwsjMzMRut7f4ORroSikA8vPziY6OJisrCxEJdjlnNWMMJSUl5Ofnk52d3eLn6ZCLUgqA+vp6EhMTNczbAREhMTHxpD8taaArpRppmLcfp/K30EBXSrUbUVFRwS6hQ9NAV0qpEKGBrpRqd4wx3HvvvQwYMICBAwfy+uuvA7B//37GjBnDkCFDGDBgAJ9//jler5eZM2c2tv3Tn/4U5OqDR89yUUod5f/+s5FN+ypbdZ390mP41ZX9W9T27bffZu3atXz77bcUFxdz3nnnMWbMGF577TUuv/xyHnzwQbxeL7W1taxdu5aCggI2bNgAQHn52fsd9bqHrpRqd5YvX8706dOxWq2kpKRw0UUXkZOTw3nnncf8+fOZM2cO69evJzo6mm7dupGbm8udd97J+++/T0xMTLDLDxrdQ1dKHaWle9Jn2pgxY/jss8949913mTlzJnfffTc/+MEP+Pbbb1myZAnPPvssCxcu5Pnnnw92qUGhe+hKqXbnwgsv5PXXX8fr9VJUVMRnn33G8OHD2b17NykpKdx8883cdNNNfP311xQXF+Pz+fj+97/P448/ztdffx3s8oNG99CVUu3O1VdfzYoVKxg8eDAiwlNPPUVqaiovvvgiv/vd77Db7URFRfHSSy9RUFDArFmz8Pl8APzmN78JcvXBI8H6xrhhw4aZ1atXB2XbSqmjbd68mb59+wa7DNVEc38TEVljjBnWXHsdclFKqRChga6UUiFCA10ppUKEBrpSSoUIDXSllAoRGuhKKRUiWhToIjJBRLaKyA4RmX2MNteJyCYR2Sgir7VumUoppU7khBcWiYgVmAuMB/KBHBFZbIzZ1KRNT+B+YLQxpkxEOrVVwUopdbo8Hg82W+hdV9mSPfThwA5jTK4xpgFYAEw5os3NwFxjTBmAMaawdctUSp0trrrqKs4991z69+/PvHnzAHj//fc555xzGDx4MJdccgkA1dXVzJo1i4EDBzJo0CDeeust4PAvyXjzzTeZOXMmADNnzuTWW29lxIgR3HfffaxatYpRo0YxdOhQzj//fLZu3QqA1+vlF7/4BQMGDGDQoEH85S9/YenSpVx11VWN6/3www+5+uqrz0R3nJSWvEVlAHubTOcDI45o0wtARL4ArMAcY8z7R65IRG4BbgHo0qXLqdSrlDoT/jsbDqxv3XWmDoQrnjxhs+eff56EhATq6uo477zzmDJlCjfffDOfffYZ2dnZlJaWAvDYY48RGxvL+vX+OsvKyk647vz8fL788kusViuVlZV8/vnn2Gw2PvroIx544AHeeust5s2bR15eHmvXrsVms1FaWkp8fDw/+clPKCoqIjk5mfnz5/OjH/3o9PqjDbTWZw4b0BO4GMgEPhORgcaYw25MbIyZB8wD/6X/rbRtpVQI+fOf/8yiRYsA2Lt3L/PmzWPMmDFkZ2cDkJCQAMBHH33EggULGp8XHx9/wnVPnToVq9UKQEVFBT/84Q/Zvn07IoLb7W5c76233to4JHNoezNmzOCVV15h1qxZrFixgpdeeqmVfuPW05JALwA6N5nODMxrKh9YaYxxA7tEZBv+gM9plSqVUmdWC/ak28Inn3zCRx99xIoVK4iIiODiiy9myJAhbNmypcXraPrlyvX19Ycti4yMbHz88MMPM3bsWBYtWkReXh4XX3zxcdc7a9YsrrzySsLCwpg6dWq7HINvyRh6DtBTRLJFxAFcDyw+os2/8e+dIyJJ+IdgcluxTqXUWaCiooL4+HgiIiLYsmULX331FfX19Xz22Wfs2rULoHHIZfz48cydO7fxuYeGXFJSUti8eTM+n69xT/9Y28rIyADghRdeaJw/fvx4/v73v+PxeA7bXnp6Ounp6Tz++OPMmjWr9X7pVnTCQDfGeIA7gCXAZmChMWajiDwqIpMDzZYAJSKyCVgG3GuMKWmropVSoWnChAl4PB769u3L7NmzGTlyJMnJycybN49rrrmGwYMHM23aNAAeeughysrKGDBgAIMHD2bZsmUAPPnkk0yaNInzzz+ftLS0Y27rvvvu4/7772fo0KGN4Q1w00030aVLFwYNGsTgwYN57bXvzsK+8cYb6dy5c7u9K6XePlcpBejtc1vijjvuYOjQofz4xz8+I9s72dvntr9BIKWUaofOPfdcIiMj+cMf/hDsUo5JA10ppVpgzZo1wS7hhPReLkopFSI00JVSKkRooCulVIjQQFdKqRChga6UUiFCA10p1SE1vavikfLy8hgwYMAZrKZ90EBXSqkQoeehK6WO8ttVv2VLactviNUSfRL68Mvhvzzm8tmzZ9O5c2duv/12AObMmYPNZmPZsmWUlZXhdrt5/PHHmTLlyK9jOL76+npuu+02Vq9ejc1m449//CNjx45l48aNzJo1i4aGBnw+H2+99Rbp6elcd9115Ofn4/V6efjhhxtvNdARaKArpdqFadOm8bOf/awx0BcuXMiSJUu46667iImJobi4mJEjRzJ58uTD7qh4InPnzkVEWL9+PVu2bOGyyy5j27ZtPPvss/z0pz/lxhtvpKGhAa/Xy3vvvUd6ejrvvvsu4L+BV0eiga6UOsrx9qTbytChQyksLGTfvn0UFRURHx9PamoqP//5z/nss8+wWCwUFBRw8OBBUlNTW7ze5cuXc+eddwLQp08funbtyrZt2xg1ahS//vWvyc/P55prrqFnz54MHDiQe+65h1/+8pdMmjSJCy+8sK1+3TahY+hKqXZj6tSpvPnmm7z++utMmzaNV199laKiItasWcPatWtJSUk56h7np+qGG25g8eLFhIeHM3HiRJYuXUqvXr34+uuvGThwIA899BCPPvpoq2zrTNE9dKVUuzFt2jRuvvlmiouL+fTTT1m4cCGdOnXCbrezbNkydu/efdLrvPDCC3n11VcZN24c27ZtY8+ePfTu3Zvc3Fy6devGXXfdxZ49e1i3bh19+vQhISGB//mf/yEuLo7nnnuuDX7LtqOBrpRqN/r3709VVRUZGRmkpaVx4403cuWVVzJw4ECGDRtGnz59TnqdP/nJT7jtttsYOHAgNpuNF154AafTycKFC3n55Zex2+2kpqbywAMPkJOTw7333ovFYsFut/O3v/2tDX7LtqP3Q1dKAXo/9PboZO+HrmPoSikVInTIRSnVYa1fv54ZM2YcNs/pdLJy5cogVRRcGuhKqQ5r4MCBrF27NthltBs65KKUUiFCA10ppUKEBrpSSoUIDXSllAoRLQp0EZkgIltFZIeIzG5m+UwRKRKRtYGfm1q/VKWU+s7x7od+tjrhWS4iYgXmAuOBfCBHRBYbYzYd0fR1Y8wdbVCjUkq1Wx6PB5utfZww2JIqhgM7jDG5ACKyAJgCHBnoSqkQceCJJ3Btbt37oTv79iH1gQeOubw174deXV3NlClTmn3eSy+9xO9//3tEhEGDBvHyyy9z8OBBbr31VnJzcwH429/+Rnp6OpMmTWLDhg0A/P73v6e6upo5c+Zw8cUXM2TIEJYvX8706dPp1asXjz/+OA0NDSQmJvLqq6+SkpJCdXU1d955J6tXr0ZE+NWvfkVFRQXr1q3j6aefBuAf//gHmzZt4k9/+tNp9S+0LNAzgL1NpvOBEc20+76IjAG2AT83xuw9soGI3ALcAtClS5eTr1YpFbJa837oYWFhLFq06Kjnbdq0iccff5wvv/ySpKQkSktLAbjrrru46KKLWLRoEV6vl+rqasrKyo67jYaGBg7dvqSsrIyvvvoKEeG5557jqaee4g9/+AOPPfYYsbGxrF+/vrGd3W7n17/+Nb/73e+w2+3Mnz+fv//976fbfUDrXVj0H+BfxhiXiPwv8CIw7shGxph5wDzw38ullbatlGplx9uTbiuteT90YwwPPPDAUc9bunQpU6dOJSkpCYCEhAQAli5dyksvvQSA1WolNjb2hIHe9JuM8vPzmTZtGvv376ehoYHs7GwAPvroIxYsWNDYLj4+HoBx48bxzjvv0LdvX9xuNwMHDjzJ3mpeSwK9AOjcZDozMK+RMaakyeRzwFOnX5pS6mxz6H7oBw4cOOp+6Ha7naysrBbdD/1Un9eUzWbD5/M1Th/5/MjIyMbHd955J3fffTeTJ0/mk08+Yc6cOcdd90033cQTTzxBnz59mDVr1knVdTwtOcslB+gpItki4gCuBxY3bSAiaU0mJwObW61CpdRZY9q0aSxYsIA333yTqVOnUlFRcUr3Qz/W88aNG8cbb7xBSYl/H/TQkMsll1zSeKtcr9dLRUUFKSkpFBYWUlJSgsvl4p133jnu9jIyMgB48cUXG+ePHz+euXPnNk4f2usfMWIEe/fu5bXXXmP69Okt7Z4TOmGgG2M8wB3AEvxBvdAYs1FEHhWRyYFmd4nIRhH5FrgLmNlqFSqlzhrN3Q999erVDBw4kJdeeqnF90M/1vP69+/Pgw8+yEUXXcTgwYO5++67AXjmmWdYtmwZAwcO5Nxzz2XTpk3Y7XYeeeQRhg8fzvjx44+77Tlz5jB16lTOPffcxuEcgIceeoiysjIGDBjA4MGDWbZsWeOy6667jtGjRzcOw7QGvR+6UgrQ+6GfaZMmTeLnP/85l1xyyTHb6P3QlVKqHSsvL6dXr16Eh4cfN8xPRfs4G14ppU5BR7wfelxcHNu2bWuTdWugK6UaGWNOeI53exLK90M/leFwHXJRSgH+i3FKSkpOKUhU6zLGUFJSQlhY2Ek9T/fQlVIAZGZmkp+fT1FRUbBLUfjfYDMzM0/qORroSikA7HZ74xWOqmPSIRellAoRGuhKKRUiNNCVUipEaKArpVSI0EBXSqkQoYGulFIhQgNdKaVChAa6UkqFCA10pZQKERroSikVIjTQlVIqRGigK6VUiNBAV0qpEKGBrpRSIUIDXSmlQoQGulJKhQgNdKWUChEtCnQRmSAiW0Vkh4jMPk6774uIEZFhrVeiUkqpljhhoIuIFZgLXAH0A6aLSL9m2kUDPwVWtnaRSimlTqwle+jDgR3GmFxjTAOwAJjSTLvHgN8C9a1Yn1JKqRZqSaBnAHubTOcH5jUSkXOAzsaYd1uxNqWUUifhtA+KiogF+CNwTwva3iIiq0VkdVFR0eluWimlVBMtCfQCoHOT6czAvEOigQHAJyKSB4wEFjd3YNQYM88YM8wYMyw5OfnUq1ZKKXWUlgR6DtBTRLJFxAFcDyw+tNAYU2GMSTLGZBljsoCvgMnGmNVtUrFSSqlmnTDQjTEe4A5gCbAZWGiM2Sgij4rI5LYu8Ehf7ijmoX+vxxhzpjetlFLtmq0ljYwx7wHvHTHvkWO0vfj0yzq23OIaXvlqDzdd0I2spMi23JRSSnUoHe5K0RHZCQCs2lUa5EqUUqp96XCB3qNTFAmRDlblaaArpVRTHS7QRYTzsuJ1D10ppY7Q4QId4LysBPaU1nKgQi9KVUqpQzpcoC/ds5TPK58CfDrsopRSTXS4QK/11PJ18RdExRSwaldJsMtRSql2o8MF+tjOY3FanXRK28zKXN1DV0qpQzpcoEfaIxmTOYYa+9dsL6xg2ZbCYJeklFLtQocLdIArsq+g1ltOZvp+/u8/G3F5vMEuSSmlgq5DBvqFGRcSYYugf89c8kpq+cdnucEuSSmlgq5DBnqYLYxxXcaxvvxzLuufwDMfb+eTrTr0opQ6u3XIQAe4qsdVVDVUcel5B+iVEs2tr6whR09jVEqdxTpsoA9PHU5WTBb/yX2bF380nPTYcH40P4cNBRXBLk0ppYKiwwa6iHBtr2tZW7SWkoY8XrlpBDHhdn74/Cp2FlUHuzyllDrjOmygA0zpPgWHxcEb294gPS6cl388HBGY+uwKvthRHOzylFLqjOrQgR4XFscV2Vfw1va3WLFvBd2So1j4v6NIjHQw458r+eOH26h36ymNSqmzQ4cOdID7ht9Hdmw2P1v2MzYWb6RbchT/vn00kwen8+ePtzPh6c/4f2sL9Fx1pVTIk2B9lduwYcPM6tWt87WjhbWFzHhvBjWeGp699FkGJA0AYPn2Yn61eAM7i2qIj7Bz5eB0Jg1KZ1jXeCwWaZVtK6XUmSQia4wxw5pdFgqBDrC3ai83f3Az5a5y5l4yl3NTzgXA5zN8sbOY51YuZ+V2Q73LSadoJxMHpnFBjySGZcUTF+FotTqUUqotnRWBDnCw5iA3fXATVQ1V/Ofq/xDtiAZgU8kmbnj3BiZmX8nImNt4d90+lm0tosHjA6BXShTDsxOYOCCNEd0Ssereu1KqnTprAh1gY/FGpr87nRv63sDs4bNx+9zc8O4NbCndQoQtgmXXLSPCHkG928u3e8vJySslJ6+M1Xml1DR4SYpyMCgzjn5pMfRLj6FfWgxdEiJ0iEYp1S4cL9BtZ7qYttY/qT/X9b6Of235F4OSBrGueB1bSrcwo98MXt70Mh/v+Zgru19JmN3KiG6JjOiWCEC928vHmwv5ePNBNu2v5NNtRXh9/je7SIeVlNgwKus8xIbbmDIkg/O7JxLusBJutxJmt5Ic7cRu7fDHmJVSHVjI7aEDVLgquHLRlZS5ygC4IusKfjvmt0x8eyIZURk8PfZpFu1YxBXZV5AUntTsOurdXnYUVrNpXyWb9ldSWFVPbLid3KIaVjbzfaYRDivDshK4vH8KU4ZkEOUMufdKpVQ7cNpDLiIyAXgGsALPGWOePGL5rcDtgBeoBm4xxmw63jrbMtDBf5B0f/V+4sPi6R7XHYtYePbbZ5m7di5pkWnsr9nPiNQRzLtsHhY5uT3rgvI6th+sot7tw+XxUuPysuVAJV/sKGZnUQ0RDiu9UqJJinKQEOkgMcpJfISdhEgn3ZIj6dkpiugwexv95kqpUHZagS4iVmAbMB7IB3KA6U0DW0RijDGVgceTgZ8YYyYcb71tHejN2Ve9j++9/T3So9IZ23ksL256kXuH3csP+v+gVdZvjGHt3nLeXJPPntJaSqobKKlxUVLdgMd3eD9nxIXTMyWK3inRZCdFEhfhIDU2jP7pMTp0o5Q6ptMdQx8O7DDG5AZWtgCYAjQG+qEwD4gEgjOOcwLpUen8+6p/0ymiE2HWMHZX7uaZr5+htL6UiztfzODkwYic+sFPEWFol3iGdok/bL4xhmqXh+LqBnYUVrPtYFXgp5ovd5Y0nm0DEG630jMlChEhIcLO0C7xpMaEUef2YhGIdNrokxpD37To06pVKRV6WrKHfi0wwRhzU2B6BjDCGHPHEe1uB+4GHMA4Y8z24603GHvoRyqpK+GB5Q+wav8qPMZD34S+zOg3g26x3bBZbORW5FLVUMWwlGE4bU7+u+u/1HnqmNprKqmRqa1Sg8fr40BlPRV1bnaX1LIyt4S8kloMcKCiju2F1TT3J0qLDaNzfARWi1Dr9lLr8jAwM5ZL+qSQlRRBcpSThEgHNt3bVyqknO6QS4sCvUn7G4DLjTE/bGbZLcAtAF26dDl39+7dJ/WLtJWqhio+yPuA+Rvns7vy+DVZxIIFCxO7TWRm/5n0jO/ZprVV1rupqHUT4bDiM1BV72b17jI+3VpESY0Lr88Q7rDhsAo5eWVU1LkbnysCseF2wu1WYsLs9E2LJj0unILyOjxew3lZ8WQnR1FZ58ZutdCjUyQRDhulNQ2U17opr2ugb1oM3ZOj2vR3VEq13OkG+ihgjjHm8sD0/QDGmN8co70FKDPGxB5vve1hD/1IXp+XzaWbKaotot5bT7fYboTbwll1YBVVDVWM7zoei1h4edPLvLX9Leo8dfRJ6EPXmK5c1eMqLsi4oHFdLq+L5QXLibZH0zuhN7HO43ZHq/B4fWzYV8mBijqKqhsornJRVttAXYOX0poGNuyroKjKRXpcOMb4D+62xAU9kuicEE5lvQcAu0WwWizYrYLVItitFqwWIdxupWtiBF0SIrBZLThtFmLD7cRG2Il22jAGKurceHyG2HA7Dpt+elDqZJ1uoNvwHxS9BCjAf1D0BmPMxiZteh4aYhGRK4FfHWuDh7THQD8Z5fXlvLHtDdYUrmF76XaK64t59PxHGZE2gkU7FvH6ltcpqS9pbB9uC6dTRCeSwpNIi0zjwowLGZM5hijHd3u/xpg2Hxf3+kzjlbB7S2s5UFlPXLid2gYvO4uqcXl8xEf4z86JdFpZurmQhWv2Uu/2Ee20IQIen8HjNXh8Prw+g9tr8PoMdW5v47n7R7JaBIHDDg5nJ0Vyad9OWETYsK+CKKeN3qkxpMQ4iQmcBeT1GZw2CzarhaIqF1X1boZnJzA4Mw4DVNa5qahzIwKZgSEopUJZa5y2OBF4Gv9pi88bY34tIo8Cq40xi0XkGeBSwA2UAXc0DfzmdPRAb6rWXctPl/2Ur/Z/hSAYDKPTR3Nj3xuxiIXtZds5WHuQ4rpiCmsL2V25m5L6EhwWB+dnnE/PuJ58XvA528u2E2mPJCUyhaHJQ7kw0x/69Z56Xt38Kg2+BiZkTaB7XPdg/8rN8nh97C2ro6CsDq8xuNxeKgKBW17rxmcMSVFObFahrMbNmj1lrNhZjCD0To2mpsFDXnENx3hPOIzDZjnsYDKA02ahT1oMI7ITsFuFlbmlVNa7SYh0YLdacHl8ZMaFM7RLHOW1brYcqCIxykHPlGgsAnUN/lNQa90e6hq8GAN902LIToqksKqeqnoP0WE2/6eOJj81Li/bC6swBjITwumWFKWfPlSbOasu/Q+WBm8Df1rzJyLtkUzpMYXO0Z2P2dZnfHxb9C0f5H3Ah7s/pLC2kCGdhjCk0xDqPfXsqdzD2qK11Lhr6BbbjWp3NYW1hVjEgs/46BHXgyuyr2BC1gS6xHQ5av1ur5tP8z9lVPooIu2Rbflrn7a6Bi8WCzhtVgBcHi/ltYG9bvx79g1eHw0eH0lRTpw2C8t3FLM+v4JI53fh6vH52H6wmnX5FazdW47XGAZlxtIp2klZjRuPz4fNaqxZGskAABQKSURBVCG3qIbiahcAnRPCKa1uoKbh8FsrO2wWIhxWvD5DVWCY6WREOW1c1CsZt9fH5gOVJEY66ZsWQ35ZLZv3V5IQ6SAzPgKPz+D1+eiVEk3vlGicdgtur+FgRT1VLg/hdisZceGM7dOJ5GjnUdupdnmwWYQwuxW310dRlYt6txefgTC7hXC7lWqXh2qXh8y4CGIjvrv2wesz1DZ4iHLaEBEq6tx4fYaESL1RXXungd6O+YyPOk/dUcHr8Xn4cPeHvLjxRewWO/cMu4fM6Ew+yPuA9/Pe55vCbwDoHd+bQcmD6BrTlUndJpEQlsBDXzzE4p2LSQpP4s6hdzKl+xSsFisf5H3A2zvexipWusd2546hd+CwNv8C9hkfL218iX6J/RieNvyUf7+NxRupcFVwfsb5p7yOk+UPNUOE4+izco0x5JfVERthJybMjs9nOFhVj0WEcIeVCLu18cwgYwx7SmvZW1pHpxgnseF2qurdjZ86Kur8B6zDAqeaWi0WdpfUsGJnCcu2FhLpsNE3PYaiKhdb9leSER/BgPQYyuvcFJTV4bBZMMDWA5XUuw//tBFmtzTOE/FftyACxvh/KuvcVLn8bzYRDmtjkB9PXISdpCj/LSpyA8Nr0U4bTruF4uoGALolRdI1MQKv8R9Qz0qMICvRP6/K5WFXUU3gQLyVbsmR9E2NweMzlNY0sKu4hoOV9XSKdpIc7cQV+ATVLTmS5CgnpbUNOKyWxrub1jV4yS2uprDKRUp0WOOpuMYYXB4fNS4P+yvqOVBRT3ykg8z4cHzG4PYY4iLtgSHA74bYjDHsr/CfMdYlIQKHzcK+8jpqXF7C7BaSor8byuvINNBD0IGaA3yQ9wFL9y5lZ/lOyl3lxDnjGJ0xmndz3+W6XtexrWwba4vW0iu+FwOSBvD29rfJjMokyhHFltItjE4fze8v+j37a/Zjs9jIislqfEE9lfMUr2x+BafVyXOXPceQTkMwxuD2ualsqGRD8QZyK3K5pMsldI3pelhthw4IL9iyoHEY6q+X/vWwg8bgv0XDLR/eQmZUJo9f8DjhtvAz2YXthsfrY39FPR6fwWYRkqOdhNmt+HyGrQer+GDjQfJKamiMLoGYMDupsWF4A2Ea6bSRGhNGhMOKCLjcPv8eeJidCIeV/LJadpfUUlrTgMvjo1tSJMnRTvZX1FPX4KVbciQ+A6vzSjlYVY/VYqGspoH8stoWDYG1lEVgdI8kYsPtfLy5kLom3yiWERdOpFPIZxGuyl5467KPuy6HzUJylJPoMBt1bi8l1Q1Uu777RGURjqo9Kcp/AV98hAOX20dJjQunzUpilIMGj4+KOjdV9R7q3V56p0bTPz2GapeHijo30U47kU4bLo8XA8SF24mLsBMX4cAiQnG1i9rAp7302LDG+0RtP1jFwcp6ymvddO8UxfndE0/rlt0a6GeBHWU7ePiLh9lQsoHvdfsev7nAfxLSkt1LeHrN0xRUF3Bj3xu559x7sFvtLNq+iDkr5mCMwQSuA+sS3YX+if2p89TxSf4nXNvrWnIO5FBaX8qgpEF8U/gNtZ7aw7ZrEQtjO4/FZ3wU1xVT667lQO0Batw1JIUnMaPfDN7NfZeDtQdZOGkh6VHpgH+I6taPbuWbwm/w+rwMSh7EkOQhLC9YzrQ+05jeZzrgf3PYUrqF3PJc4pxxdI3tSrfYbofVsPrAatYcXMOw1GEMSh6E3XLivTBjDJ8XfM7ApIHEh8VTVl/Gc+ufw2qxkhaZRq/4XvRN6EuEPeK0/zbtgTGGkvqSY9676FgaPL7GN4OoMBvZSZE4bBZqXd7GC+ScNv9ed9fECFJjwyiqclFU5SLcbsVrDDsLqymubiApysGBynr+39p91DZ4uWJAKqN7JJES42RnYQ0fbT5IrnmFg3xMpDWBmV3/Ste4BFJjwyirbWBfeT02i//MqvJaN8XVLoqqXVTWeYhwWEmIdNC9UxRx4Xb2lNZS7/bSOSGCmEDgH6x0sauohsKqespq3ThtFiIjajDeKMpqvDhtFmLC/Z/c7FZhfUEF2w5WNQ7rVbs81Lj87eC7M7ZOlkXg0SkD+J+RXU/cuBka6GcJj89DzoEchqUMw279LtRcXhe7K3fTK77XYe2/KPiCr/Z/Ra/4XtS6a1mWv4y9lXup89RxWdZl3Hfefeyv2c+dS+/EGMO5KeeSEpFChD2CPgl9SItM47XNr/HerveIdcbSKaITkfZIEsISGNd5HMPThmOz2NhTuYfr37kei8XCgKQBxNhjyK3IZWvZVp688EmcVie//OyX+PCREZXB7srd3D/8fipcFczfOJ86z+GnV56ffj4/GvAjwm3hvJ/3Pi9verlxmVWsdIroRO+E3nwv+3sg8EHeB9S4a0iNTGVk2kjGdh7Lk6ue5K3tb9E5ujNPjXmKOV/OYWf5TkQEt89/Lr9NbFzc+WKm9JjCiLQRhNvCcXvduH3uZoPeZ3x4fB7sFjsiQkF1Abd/dDsDkgbwi2G/IC4srkV/x4M1B/m84HM8Pg/d47pzXup5jesXpHGYYXPJZmKcMWREZTQ+d1/1PpbtXcao9FGNb3wur4tHvniE93a9x8MjH+a63te1qI62trdyLy6vix7xPTDG8MLGF/jjmj9yaZdL+XjPx9zQ9wbuO+8+9lbtJSMqA5vl1G9499X+rwizhjGk0xAAiuuK+cs3f2HR9kVM7DaRJy98stnnHe/Ms0NXgJfX+o8/JEU7iXT4jwXtLKphZW4xNquFXinRZMSHExNmZ+O+Cj7fXsxl/VLplx5zSr+LBroKurWFa3lj2xtsLd1KnaeOxPBEJnWb1BguFa4KLGIhzBrGXcvuYnnBcgAu63oZE7Mn0jO+J5UNleQcyOH5Dc9T7ipvXPf1va/nlkG3sLZoLZtLNrO/Zj+r9q+isK4QgKTwJFIjUimoLqDMVUa4LZw6Tx3f7/l9PtrzERWuChwWB38Z9xdGpY+isLaQLaVbWHlgJe/sfIcyVxl2i530qHQKqgpA4IKMC5iYPZGLMi9iZ/lOHvvqMTaXbgZgUNIgbh9yO0+seoLiumJcHhdRjihSIlIod5VjMDitTsZ3Hc+UHlOodFVSVl9Gj/ge7CjbwUNfPERlw3d303hwxIOMTBvJPZ/eQ1VDFTf2vZGNxRv5b95/sYmN7/f6PknhSawtWsuKfSvwGR82sXFd7+tIjkhm2d5lrCtaR4+4Huwo38GcUXO4qsdVWC3Ww/5GPuOjwlWBzWJr/HKYpjw+D0vylpAQlsDw1OFHPb9pu4LqAjpHd8YilsZPbV2juzY+J7c8lx+8/wMqXBVc1vUyiuqK+KbwGy7pcgl/uOgPPLnqSRZuW0hyeDIHaw/SP7E/T1z4xFGfzj7d+ynLC5Zzba9r6Z3Qu9lanvn6GV7Y+AIRtggWTFqAVazM+O8MKhsqGZw8mDUH1/DUmKe4IvuKw567r3ofOQdy6JPQh4SwBOZvnM+W0i3cMugWRqaNpKi2iMK6QnrF9aLcVc7CbQtZX7Se4rpiiuuKKXOVMSBxAPeedy+DkwdT56kj3BZ+2qcma6CrDqXeU88/N/yTEakjGJZ69P/b6oZqcg7kYLPYSI1MbfZqXa/Py9eFXwNwTqdzsFqs+IyPz/M/581tbzKuyziu7nk1uRW5PLXqKWb0m8HojNFHrcftdbPqwCpW7FtBfnU+2bHZuLwuluQtobC2kHBbOPWeepIjkpnSfQoWsfDGtjcorS8lzBrGPy77B+G2cP669q94jZdYZyw2i43iumKWFyzHZ3xHbbNvQl8eHf0oCWEJPLbiMT7J/4QwaxhhtjC6xXbj68KvcVgc/HjgjymtL+XNbW/iNV6yYrK4tOulXNb1Ml7f+jpvb38bgyHGEcPDox5mbOex3PHxHXy1/yui7FH0iOuBRSy4vC6K64opqSvBY/xj0BlRGY3DM1kxWYxKH8VrW15jXdE6AJLDk8mMzsRpdeK0OomwRZAVm+UPza0LKKguIDUylR5xPcg5kIPL6yLcFs6gpEFcmHkhr2x+BbfXzeTuk1mwdQHhtnDuGnpX4xtNVUMV//vh/5IYlsjgToN5ceOL1HnqmDVgFrP6z2JXxS5e2PgC7+e9jwSOLgxPG05hbSHFtcU4rA4MhqqGKtw+N9f0vIZle5aRGJ6Iy+uiqqGK+ZfPJys2ix++/0N2VexiROoI1hevJ8YZQ6Qtkm+Lvm0cjgT/p7/EsEQK6wrpGd+THWU7Gt+cvcaL1+elT0IfUiJSSAxPJMYRw7u571JYV4hVrI1/o/Fdx3Nl9yvJjj3+MYJj0UBXqpX5jI81B9ewJG8JUfYobhp4U+NFYhWuCl7c+CIj00Ye9wyhguoCvij4gpSIFGKdsWwv306Dt4Fre12L0+o/TdHtczPnyzkcqDnA46MfJy0qja2lW4l2RDcejyitL8VhcRx2kRr4b2lhs9gOO9js8rr4IO8D1hauJa8yDwC71U5yeDJJ4UkkhSdR56lja+lWKlwV+PCxqXgTVe4qYhwxzB4+G4fVwYe7P6S8vpx6bz0ur4vqhmoKqgswGAYlD2JC1gRW7l/JropdjM4YTd+Evmwt28rK/SvZUb6DSHsk8y+fT9/EvtS6a7FarI2/c3OK64p5ctWTLMlbgs1iaxzaumXQLVzb61rmb5jPl/u+pEt0F1IiU/D4/G9MUY4ohiYPZWyXsXxR8AW3fXQbDquDf17+TwYnDwb8Qz/Xv3s90Y5oBicPptZTS0ldCaMzRjO281i2lW1jb9VepnSfQqeITjz77bOsObiG8zPOJzs2m3VF67CJjam9ptI55vDTlWvdtbyx7Q0qXBWE2cLIOZBDzoEcHhn1CNf0vKYl/9WOooGulDplbq+bdcXr6BrT9bgHVWvdtZTUl5AZlXncYYU9lXuwiIXM6MyTrmVt4Vr+s/M/DEgawNjOY1t8XOKQD3d/SGJYIueknHPYfK/Pe8whpNZWVl/m/1RzigfcNdCVUipEHC/Q9fpkpZQKERroSikVIjTQlVIqRGigK6VUiNBAV0qpEKGBrpRSIUIDXSmlQoQGulJKhYigXVgkIkXA7lN8ehJQ3IrltKb2Wlt7rQvab23ttS5ov7W117ogdGrraoxJbm5B0AL9dIjI6hN9CXWwtNfa2mtd0H5ra691Qfutrb3WBWdHbTrkopRSIUIDXSmlQkRHDfR5wS7gONprbe21Lmi/tbXXuqD91tZe64KzoLYOOYaulFLqaB11D10ppdQROlygi8gEEdkqIjtEZHYQ6+gsIstEZJOIbBSRnwbmJ4jIhyKyPfBvfBBrtIrINyLyTmA6W0RWBvrudRFxBKGmOBF5U0S2iMhmERnVXvpMRH4e+FtuEJF/iUhYsPpMRJ4XkUIR2dBkXrP9JH5/DtS4TkTOOfaa26Su3wX+nutEZJGIxDVZdn+grq0icnlb1XWs2posu0dEjIgkBaaD2meB+XcG+m2jiDzVZP6p95kxpsP8AFZgJ9ANcADfAv2CVEsacE7gcTSwDegHPAXMDsyfDfw2iP11N/Aa8E5geiFwfeDxs8BtQajpReCmwGMHENce+gzIAHYB4U36amaw+gwYA5wDbGgyr9l+AiYC/wUEGAmsPMN1XQbYAo9/26SufoHXqBPIDrx2rWeytsD8zsAS/Ne9JLWTPhsLfAQ4A9OdWqPPzuiLphU6ZhSwpMn0/cD9wa4rUMv/A8YDW4G0wLw0YGuQ6skEPgbGAe8E/uMWN3nhHdaXZ6im2EBoyhHzg95ngUDfCyQAtkCfXR7MPgOyjgiBZvsJ+Dswvbl2Z6KuI5ZdDbwaeHzY6zMQqqPOZJ8F5r0JDAbymgR6UPsM/47Cpc20O60+62hDLodedIfkB+YFlYhkAUOBlUCKMWZ/YNEBICVIZT0N3Acc+lr5RKDcmMDXugen77KBImB+YCjoORGJpB30mTGmAPg9sAfYD1QAawh+nzV1rH5qT6+LH+Hf84V2UJeITAEKjDHfHrEo2LX1Ai4MDOd9KiLntUZdHS3Q2x0RiQLeAn5mjKlsusz432LP+GlEIjIJKDTGrDnT2z4BG/6Pnn8zxgwFavAPHTQKYp/FA1Pwv+mkA5HAhDNdR0sFq5+OR0QeBDzAq8GuBUBEIoAHgEeCXUszbPg/DY4E7gUWyvG+WbuFOlqgF+AfDzskMzAvKETEjj/MXzXGvB2YfVBE0gLL04DCIJQ2GpgsInnAAvzDLs8AcSJiC7QJRt/lA/nGmJWB6TfxB3x76LNLgV3GmCJjjBt4G38/BrvPmjpWPwX9dSEiM4FJwI2BN5v2UFd3/G/Q3wZeC5nA1yKS2g5qywfeNn6r8H+STjrdujpaoOcAPQNnHjiA64HFwSgk8G76T2CzMeaPTRYtBn4YePxD/GPrZ5Qx5n5jTKYxJgt/Hy01xtwILAOuDVZtxpgDwF4R6R2YdQmwiXbQZ/iHWkaKSETgb3uotqD22RGO1U+LgR8EztwYCVQ0GZppcyIyAf/w3mRjTO0R9V4vIk4RyQZ6AqvOVF3GmPXGmE7GmKzAayEf/4kMBwhynwH/xn9gFBHphf8EgWJOt8/a8gBFGx1cmIj/jJKdwINBrOMC/B951wFrAz8T8Y9Vfwxsx38UOyHI/XUx353l0i3wn2MH8AaBI+xnuJ4hwOpAv/0biG8vfQb8H7AF2AC8jP9Mg6D0GfAv/GP5bvxB9ONj9RP+A95zA6+J9cCwM1zXDvzjvodeB882af9goK6twBVnus+OWJ7HdwdFg91nDuCVwP+1r4FxrdFneqWoUkqFiI425KKUUuoYNNCVUipEaKArpVSI0EBXSqkQoYGulFIhQgNdKaVChAa6UkqFCA10pZQKEf8f8rorJRRGsfsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F70i7ZseZ8RH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aaa2849-f69f-4a7d-aa7a-8a323668858e"
      },
      "source": [
        "val_loss,val_acc = model.evaluate(X_cv,y_cv)\n",
        "print(val_loss)\n",
        "print(val_acc)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2363/2363 [==============================] - 3s 1ms/step - loss: 0.2636 - accuracy: 0.8769\n",
            "0.2636033296585083\n",
            "0.8768783211708069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT0zHR9WZ8V3"
      },
      "source": [
        "pred = np.argmax(model.predict(X_cv),-1)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5WFtIpA4iwm",
        "outputId": "4bcc6ea2-983c-4b85-9603-9e2c6bfcae7e"
      },
      "source": [
        "THRESHOLD = 0.115\n",
        "pred = np.where(model.predict_proba(X_cv) > THRESHOLD, 1, 0)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgj48lyvZ8al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a129c767-ec67-4f90-b73e-147b23aecea7"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score,accuracy_score,confusion_matrix,classification_report\n",
        "\n",
        "print(roc_auc_score(y_cv,pred))\n",
        "print()\n",
        "print(accuracy_score(y_cv,pred))\n",
        "print()\n",
        "print(confusion_matrix(y_cv,pred))\n",
        "print()\n",
        "print(classification_report(y_cv,pred))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8329160732046375\n",
            "\n",
            "0.8089285714285714\n",
            "\n",
            "[[53106 13186]\n",
            " [ 1259  8049]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.80      0.88     66292\n",
            "           1       0.38      0.86      0.53      9308\n",
            "\n",
            "    accuracy                           0.81     75600\n",
            "   macro avg       0.68      0.83      0.70     75600\n",
            "weighted avg       0.90      0.81      0.84     75600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoB9Fb4240_X",
        "outputId": "ab737c6b-5109-4c0f-b9a0-62c717f5719f"
      },
      "source": [
        "THRESHOLD = 0.115\n",
        "pred = np.where(model.predict_proba(df_test) > THRESHOLD, 1, 0)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozuPZAjb400h"
      },
      "source": [
        "pred = pd.DataFrame(pred)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yt1iNm640qc"
      },
      "source": [
        "index = pd.DataFrame(range(1,28001))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRmjyVtr40gw"
      },
      "source": [
        "index = pd.concat([index,pred],axis=1)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XQdjY6S40Zp"
      },
      "source": [
        "index.columns = ['id','risk_flag']"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBA1_EIs40O5"
      },
      "source": [
        "index.set_index('id',inplace=True)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0sgrPld40Dn"
      },
      "source": [
        "index.to_csv('result_4.csv')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "IcRwahKK4z7b",
        "outputId": "d0ca34fe-2ddc-4e74-fcd6-08627378f25f"
      },
      "source": [
        "index"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>risk_flag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27996</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27997</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27998</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27999</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28000</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       risk_flag\n",
              "id              \n",
              "1              0\n",
              "2              0\n",
              "3              0\n",
              "4              0\n",
              "5              0\n",
              "...          ...\n",
              "27996          0\n",
              "27997          0\n",
              "27998          0\n",
              "27999          1\n",
              "28000          1\n",
              "\n",
              "[28000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}